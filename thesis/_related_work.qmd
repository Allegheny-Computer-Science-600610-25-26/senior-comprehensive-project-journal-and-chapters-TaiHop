# Related work

## Data Manipulation in Analytical Systems

When people build systems that analyze large volumes of data, it is rarely enough to simply “collect and store” the data. You usually need a full pipeline that extracts raw inputs, cleans or transforms them, and then loads them into a database or analysis system. This process, often called ETL (extract-transform-load, or in modern contexts, variant pipelines) ensures that data is accurate, consistent, and in the right format for analysis. But recent research shows that these pipelines are often fragile and have a good amount of errors. In a large study, engineers identified 41 different factors that influence whether a data pipeline produces high-quality data, such as the variety of data sources, the complexity of transformations, mismatch of data types, and insufficient checks during cleaning and ingestion. [@DataPipelineQuality2023]

Many of the data problems tend to happen early on especially during the “cleaning” stage, when raw inputs are standardized, and during “ingestion/integration,” when data from different sources are combined. [@DataPipelineQuality2023]  If a pipeline is not carefully designed with validation steps, schema definitions (clear rules for what fields and data types are expected), and metadata or provenance tracking (records of where each piece of data came from and how it was transformed) then errors can silently corrupt the dataset. This is why transparency plays a major concept of DataSeekr. Below is a figure of a clean high level pipeline:

![High level pipeline](images/pipeline.png)

For sports data which can include traditional box score stats, lists of matches, roster databases, video metadata, wearable sensor outputs, etc. this fragility is especially concerning. The mixture of structured, semi-structured, and unstructured data means that schema mismatches, missing fields, or mistyped data are likely, and without proper pipeline safeguards, derived metrics (like “player performance” or “projectability”) risk being misleading. A system like DataSeekr that defines a stable ingestion schema, stores raw as well as transformed data, and logs transformations offers a more reliable foundation for analytics than scraping and manual manipulation.

## Sports Analytics and Athlete-Evaluation Technologies

In recent years, the field of sports analytics has expanded far beyond traditional box scores and basic statistics. Researchers and practitioners increasingly use wearable sensors (like GPS trackers or accelerometers), motion data, and computer vision algorithms on video to analyze biomechanical performance, movement patterns, positional data, and even predict injuries or long term workload. [@AIWearables2024] This is especially true for higher division and higher funded schools as they measure more as they have the technology. However this is more for training purposes only.

Moreover, machine learning (ML) and artificial intelligence (AI) methods are being applied to these data: deep learning models, for example, it can process sensor signals or video frames to automatically detect events (a sprint, a jump, a shot), track trajectories, or talk about workload and stress patterns. [@WearableSportsReview2024 ] This promises to give much richer, more nuanced insight into athletic performance than classical statistics for example, quantifying not just how many hits or hits per game, but movement efficiency, reaction times, recovery patterns, or biomechanical risk factors. However these same technologies aren't offered or are too expensive for lower division schools.

However, despite the promise, there remain serious limitations. Many studies have small sample sizes, sometimes only lab based trials, or focus on a narrow subset of athletes under controlled conditions. That makes it hard to know whether conclusions generalize to real-world, competitive settings or different populations. [@AIWearables2024]  Also, variability in sensor hardware, sampling frequency, calibration protocols, and preprocessing methods across studies means combining or comparing results across different teams or contexts is very difficult. For instance, what “acceleration pattern X” means in one study might be incompatible with another’s data because of different sensor settings or cleaning methods. [@DeepLearningAthlete2023] Thus calling for a centralized and managed output that can be implemented into their own work.

Because of these issues reproducibility, generalizability, and high technical access cost, advanced wearables/vision-based analytics remain largely confined to elite or well-funded sports organizations. Many lower-division or less resourced programs (high school, small colleges, semi-pro leagues) simply cannot adopt them, which perpetuates inequality in access.

In contrast, a tool like DataSeekr that relies on publicly available data (e.g. game stats, official records) rather than specialized sensors or advanced hardware can be broadly used. While it sacrifices some of the rich detail that wearable/vision systems offer, it gains in accessibility, scalability, and fairness allowing more athletes to benefit, regardless of resources.

## Web Scraping and Automated Data Collection

“Web scraping” means using automated software (bots) to retrieve data from web pages, parse relevant information, and store it in a structured form (e.g. CSV, database). For sports analytics, web scraping is often an attractive way to collect publicly available statistics, game logs, roster listings, highlight-video metadata, schedules, and more especially when no official API or bulk-export feature exists.

But scraping comes with serious ethical, legal, and technical considerations. Even if the data are public in principle, a website’s terms of service may forbid automated scraping or bulk harvesting. There are also potential copyright or database right issues, especially if the site collects and compiles data. According to recent research, as scraping becomes more widespread (for example to feed large language models or AI training sets), many site owners are tightening policies, making scraping riskier. [@EthicsScraping2024]

Beyond legal risks, scraping can impose real burdens on websites. If many bots crawl a site rapidly, it can degrade performance, cause partial outages, or trigger blocking. Ethical guidelines for responsible scraping recommend respecting rate-limits (delays between requests), obeying robots exclusion rules (robots.txt), avoiding repeated heavy access, and documenting provenance (where the data came from, when it was collected). [@EthicsScraping2024]

For DataSeekr, building a scraping-based ingestion system means you must embed these ethical/legal safeguards. By limiting collection to publicly available data, avoiding redistribution of copyrighted content, documenting provenance, and respecting site load, you reduce legal and ethical risk. That makes your system far more defensible than a “scrape first, ask forgiveness later” approach.

## Limitations of Existing Athlete Platforms

Many existing athlete platforms, whether they host highlight videos, recruiting profiles, or analytics dashboards offer useful services for players, coaches, and scouts. However, these platforms have structural limitations that make them imperfect tools for fair and broad talent discovery. These sites might give recommendations which is good but also creates an imbalance or a sense of unfairness.

Platforms often suffer from data lock-in. Once a player uploads their video or stats to that platform, exporting them in bulk, or integrating them with independent tools, can be difficult or forbidden by the platform’s terms. This limits portability and makes independent validation or custom analysis hard. This more impacts the player as this can reduce a bunch of opportunities for them as some prices which i have discovered first hand. This is because I am an athlete, I used a service that had a super high payment cost which really deferred other options because I didn't have that many funds. This is just one real world example of this happening. 

There is a significant visibility bias. Players from well resourced or high visibility programs tend to get more filming, better video quality, more highlight clips  which increases their exposure by default. Meanwhile, players from smaller schools or lower divisions may perform just as well but lack the video, the editors, or the promotion to catch scouts’ eyes. This creates structural inequality in exposure opportunities. To think of this, imagine a player at Allegheny, no guarantee to be recorded and the event mostly likely won't be on television, whereas someone at LSU would have their games being broadcasted to millions of people. This creates a major bias within the recruitment world.

Many platforms provide opaque or proprietary metrics. They might display a “player grade”,  “efficiency rating”,  or “projectability score” but without exposing raw data or the algorithm behind them. Without transparency, it’s impossible for coaches or third-party analysts to verify or challenge those scores, compare across platforms, or adapt them to different contexts. Because of these limitations, many talented athletes slip through the cracks simply because they don’t have the right profile on the “right” platform. A system like DataSeekr which aggregates publicly available data, provides raw and derived metrics in a transparent, uniform schema, and avoids reliance on platform specific video uploads offers an alternative. By leveling the “exposure playing field,” it helps reduce bias and gives scouts a more equitable view of players from all backgrounds.

## Gaps in Current Research and How DataSeekr Contributes

Even though sports analytics, data pipelines, and automated evaluation tools have grown quickly in recent years, there are still major gaps that make it hard for athletes, coaches, and researchers to work with data in a consistent and fair way. One of the most important problems is that there is no shared standard for sports data. Different projects collect data in different ways: some rely on wearable sensors, some use video-based tracking, and others manually gather box scores from websites. Each of these sources uses its own format, structure, and terminology. Because of this, it becomes very difficult to combine information from multiple sources or compare results between teams or seasons. Without standardization, long-term studies and reproducible research are often impossible, a challenge discussed widely in sports-analytics literature.

Another gap is related to data engineering, not just analysis. Many research papers or small projects collect data only once, in a short window of time. They rarely build long-term, maintainable data pipelines that can update information automatically. As a result, the data may slowly become outdated, inconsistent, or corrupted. This is a serious problem for sports analytics, since understanding athlete development or performance trends often requires reliable data over several years. If a system does not track where the data came from, when it was updated, and how it was cleaned, then later analysis may be inaccurate.

There is also a growing concern about ethics, legality, and data rights. Many sports-analytics systems collect data from websites without clearly documenting their methods. Some projects scrape information even when a website’s terms of service prohibit automated collection. Others combine athlete statistics with personal information without considering privacy rules or the athlete’s consent. According to recent studies on web data ethics, scraping without transparency or permission can violate site policies and raise legal risks for researchers or developers [@Akinwande2024ScrapingEthics]. These problems show that sports-data systems need better documentation, clearer permissions, and more ethical standards.

DataSeekr is designed specifically to address these gaps. Instead of depending on expensive wearable devices or privileged school resources, DataSeekr collects only publicly available information. It uses a clear and transparent pipeline that moves data from scraping → CSV → database → visualization. Every step is documented so users know exactly how the data was collected and processed. The system also exports data in a consistent, well-defined schema, which makes it easier for others to reuse the information or build additional tools on top of it.

Because DataSeekr focuses on standardization, accessibility, and transparency, it provides a more democratic alternative to many existing athlete-evaluation platforms. It allows schools, teams, and athletes especially those with fewer resources to access high-quality analytics without needing expensive equipment or special data sources. In the long term, DataSeekr could support broader research studies, help track athletes across multiple seasons, and encourage more open and fair practices in scouting and player evaluation.
