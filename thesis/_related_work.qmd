# Related work

## Data Manipulation in Analytical Systems

When people build systems that analyze large volumes of data, it is rarely enough to simply “collect and store” the data. You usually need a full pipeline that extracts raw inputs, cleans or transforms them, and then loads them into a database or analysis system. This process, often called ETL (extract-transform-load, or in modern contexts, variant pipelines) ensures that data is accurate, consistent, and in the right format for analysis. But recent research shows that these pipelines are often fragile and have a good amount of errors. In a large study, engineers identified 41 different factors that influence whether a data pipeline produces high-quality data, such as the variety of data sources, the complexity of transformations, mismatch of data types, and insufficient checks during cleaning and ingestion. [@DataPipelineQuality2023]

Many of the data problems tend to happen early on especially during the “cleaning” stage, when raw inputs are standardized, and during “ingestion/integration,” when data from different sources are combined. [@DataPipelineQuality2023]  If a pipeline is not carefully designed with validation steps, schema definitions (clear rules for what fields and data types are expected), and metadata or provenance tracking (records of where each piece of data came from and how it was transformed) then errors can silently corrupt the dataset. This is why transparency plays a major concept of DataSeekr. Below is a figure of a clean high level pipeline:

![High level pipeline](images/pipeline.png)

For sports data which can include traditional box score stats, lists of matches, roster databases, video metadata, wearable sensor outputs, etc. this fragility is especially concerning. The mixture of structured, semi-structured, and unstructured data means that schema mismatches, missing fields, or mistyped data are likely, and without proper pipeline safeguards, derived metrics (like “player performance” or “projectability”) risk being misleading. A system like DataSeekr that defines a stable ingestion schema, stores raw as well as transformed data, and logs transformations offers a more reliable foundation for analytics than scraping and manual manipulation.

## Sports Analytics and Athlete-Evaluation Technologies

In recent years, the field of sports analytics has expanded far beyond traditional box scores and basic statistics. Researchers and practitioners increasingly use wearable sensors (like GPS trackers or accelerometers), motion data, and computer vision algorithms on video to analyze biomechanical performance, movement patterns, positional data, and even predict injuries or long term workload. [@AIWearables2024] This is especially true for higher division and higher funded schools as they measure more as they have the technology. However this is more for training purposes only.

Moreover, machine learning (ML) and artificial intelligence (AI) methods are being applied to these data: deep learning models, for example, it can process sensor signals or video frames to automatically detect events (a sprint, a jump, a shot), track trajectories, or talk about workload and stress patterns. [@WearableSportsReview2024 ] This promises to give much richer, more nuanced insight into athletic performance than classical statistics for example, quantifying not just how many hits or hits per game, but movement efficiency, reaction times, recovery patterns, or biomechanical risk factors. However these same technologies aren't offered or are too expensive for lower division schools.

However, despite the promise, there remain serious limitations. Many studies have small sample sizes, sometimes only lab based trials, or focus on a narrow subset of athletes under controlled conditions. That makes it hard to know whether conclusions generalize to real-world, competitive settings or different populations. [@AIWearables2024]  Also, variability in sensor hardware, sampling frequency, calibration protocols, and preprocessing methods across studies means combining or comparing results across different teams or contexts is very difficult. For instance, what “acceleration pattern X” means in one study might be incompatible with another’s data because of different sensor settings or cleaning methods. [@DeepLearningAthlete2023] Thus calling for a centralized and managed output that can be implemented into their own work.

Because of these issues reproducibility, generalizability, and high technical access cost, advanced wearables/vision-based analytics remain largely confined to elite or well-funded sports organizations. Many lower-division or less resourced programs (high school, small colleges, semi-pro leagues) simply cannot adopt them, which perpetuates inequality in access.

In contrast, a tool like DataSeekr that relies on publicly available data (e.g. game stats, official records) rather than specialized sensors or advanced hardware can be broadly used. While it sacrifices some of the rich detail that wearable/vision systems offer, it gains in accessibility, scalability, and fairness allowing more athletes to benefit, regardless of resources.

## Web Scraping and Automated Data Collection

“Web scraping” means using automated software (bots) to retrieve data from web pages, parse relevant information, and store it in a structured form (e.g. CSV, database). For sports analytics, web scraping is often an attractive way to collect publicly available statistics, game logs, roster listings, highlight-video metadata, schedules, and more especially when no official API or bulk-export feature exists.

But scraping comes with serious ethical, legal, and technical considerations. Even if the data are public in principle, a website’s terms of service may forbid automated scraping or bulk harvesting. There are also potential copyright or database right issues, especially if the site collects and compiles data. According to recent research, as scraping becomes more widespread (for example to feed large language models or AI training sets), many site owners are tightening policies, making scraping riskier. [@EthicsScraping2024]

Beyond legal risks, scraping can impose real burdens on websites. If many bots crawl a site rapidly, it can degrade performance, cause partial outages, or trigger blocking. Ethical guidelines for responsible scraping recommend respecting rate-limits (delays between requests), obeying robots exclusion rules (robots.txt), avoiding repeated heavy access, and documenting provenance (where the data came from, when it was collected). [@EthicsScraping2024]

For DataSeekr, building a scraping-based ingestion system means you must embed these ethical/legal safeguards. By limiting collection to publicly available data, avoiding redistribution of copyrighted content, documenting provenance, and respecting site load, you reduce legal and ethical risk. That makes your system far more defensible than a “scrape first, ask forgiveness later” approach.

## Limitations of Existing Athlete Platforms

Many existing athlete platforms provide helpful tools such as highlight video hosting, recruiting profiles, and analytics dashboards. These platforms can be useful for players, coaches, and scouts because they allow athletes to share their performance and communicate with teams. However, even though these systems offer valuable features, they also contain problems that make them less fair and less effective for discovering talent across all levels of competition. These issues often make athletes feel that the process is unbalanced or biased.

One of the biggest challenges is something known as data lock in. This means that once an athlete uploads their videos or statistics to a specific platform, it becomes very difficult to move that information anywhere else. Some platforms do not allow exporting data at all, and others charge high prices for features that should be basic, such as downloading your own clips in high quality. This affects athletes directly. In my own experience, I used a recruiting service that required a very expensive payment to access the tools I needed. Since I did not have the money at the time, I missed opportunities that other players with more financial resources could access. Many athletes face similar obstacles, which limits fairness in the recruiting process.

Another issue is the difference in visibility between large, well funded programs and smaller schools. Athletes at major universities often appear on television, have dedicated camera crews, and receive high quality highlights automatically. Their plays look more professional, which naturally attracts more views and interest from scouts. Students at smaller colleges or high schools do not have this advantage. Their games may not be recorded, or the recordings may be low quality. For example, a player at a school like Allegheny might only have a few inconsistent videos, while a player at LSU will have every game broadcast and available online. This creates a major difference in visibility that has nothing to do with skill or performance. Instead, it is based on resources and exposure.

A third problem is the use of closed or proprietary evaluation systems. Some platforms give athletes a “player grade” or a “projectability score,” but they do not explain how these numbers were created. Without knowing the data behind the score or how the algorithm works, coaches and analysts cannot trust or verify what the rating means. This lack of transparency makes it difficult to compare players fairly. An athlete could receive a low rating for reasons that are not explained, which can negatively affect their chances even if they are talented.

Because of these limitations, many strong athletes remain overlooked simply because they lack access to high quality video, expensive subscriptions, or the right platform. DataSeekr aims to reduce this inequality. Instead of depending on paid uploads or hidden formulas, DataSeekr gathers publicly available information, organizes it in a consistent and clear structure, and provides both raw and calculated metrics in a transparent way. This creates a fairer environment where athletes from any background can be evaluated on their actual performance rather than on money, exposure, or platform design.

By presenting the data openly and treating every athlete the same, DataSeekr helps create a more equal recruiting landscape. Coaches and scouts can make better decisions because they are working with clean and trustworthy information. This approach gives athletes from all schools, big or small, a more realistic chance to be recognized.

## Gaps in Current Research and How DataSeekr Contributes

Even though sports analytics, data pipelines, and automated evaluation tools have grown quickly in recent years, there are still major gaps that make it hard for athletes, coaches, and researchers to work with data in a consistent and fair way. One of the most important problems is that there is no shared standard for sports data. Different projects collect data in different ways: some rely on wearable sensors, some use video-based tracking, and others manually gather box scores from websites. Each of these sources uses its own format, structure, and terminology. Because of this, it becomes very difficult to combine information from multiple sources or compare results between teams or seasons. Without standardization, long-term studies and reproducible research are often impossible, a challenge discussed widely in sports-analytics literature.

Another gap is related to data engineering, not just analysis. Many research papers or small projects collect data only once, in a short window of time. They rarely build long-term, maintainable data pipelines that can update information automatically. As a result, the data may slowly become outdated, inconsistent, or corrupted. This is a serious problem for sports analytics, since understanding athlete development or performance trends often requires reliable data over several years. If a system does not track where the data came from, when it was updated, and how it was cleaned, then later analysis may be inaccurate.

There is also a growing concern about ethics, legality, and data rights. Many sports-analytics systems collect data from websites without clearly documenting their methods. Some projects scrape information even when a website’s terms of service prohibit automated collection. Others combine athlete statistics with personal information without considering privacy rules or the athlete’s consent. According to recent studies on web data ethics, scraping without transparency or permission can violate site policies and raise legal risks for researchers or developers [@Akinwande2024ScrapingEthics]. These problems show that sports-data systems need better documentation, clearer permissions, and more ethical standards.

DataSeekr is designed specifically to address these gaps. Instead of depending on expensive wearable devices or privileged school resources, DataSeekr collects only publicly available information. It uses a clear and transparent pipeline that moves data from scraping → CSV → database → visualization. Every step is documented so users know exactly how the data was collected and processed. The system also exports data in a consistent, well-defined schema, which makes it easier for others to reuse the information or build additional tools on top of it.

Because DataSeekr focuses on standardization, accessibility, and transparency, it provides a more democratic alternative to many existing athlete-evaluation platforms. It allows schools, teams, and athletes especially those with fewer resources to access high-quality analytics without needing expensive equipment or special data sources. In the long term, DataSeekr could support broader research studies, help track athletes across multiple seasons, and encourage more open and fair practices in scouting and player evaluation.
