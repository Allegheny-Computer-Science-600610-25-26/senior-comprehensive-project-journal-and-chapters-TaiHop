# Related work

## Data Manipulation in Analytical Systems

When people build systems that analyze large volumes of data, it is rarely enough to simply “collect and store” the data. You usually need a full pipeline that extracts raw inputs, cleans or transforms them, and then loads them into a database or analysis system. This process, often called ETL (extract-transform-load, or in modern contexts, variant pipelines) ensures that data is accurate, consistent, and in the right format for analysis. But recent research shows that these pipelines are often fragile and have a good amount of errors. In a large study, engineers identified 41 different factors that influence whether a data pipeline produces high-quality data, such as the variety of data sources, the complexity of transformations, mismatch of data types, and insufficient checks during cleaning and ingestion. [@DataPipelineQuality2023]

Many of the data problems tend to happen early on especially during the “cleaning” stage, when raw inputs are standardized, and during “ingestion/integration,” when data from different sources are combined. [@DataPipelineQuality2023]  If a pipeline is not carefully designed with validation steps, schema definitions (clear rules for what fields and data types are expected), and metadata or provenance tracking (records of where each piece of data came from and how it was transformed) then errors can silently corrupt the dataset. This is why transparency plays a major concept of DataSeekr. Below is a figure of a clean high level pipeline:

![High level pipeline](images/pipeline.png)

For sports data which can include traditional box score stats, lists of matches, roster databases, video metadata, wearable sensor outputs, etc. this fragility is especially concerning. The mixture of structured, semi-structured, and unstructured data means that schema mismatches, missing fields, or mistyped data are likely, and without proper pipeline safeguards, derived metrics (like “player performance” or “projectability”) risk being misleading. A system like DataSeekr that defines a stable ingestion schema, stores raw as well as transformed data, and logs transformations offers a more reliable foundation for analytics than scraping and manual manipulation.

## Sports Analytics and Athlete-Evaluation Technologies

In recent years, the field of sports analytics has grown far beyond traditional box scores and basic statistics. Modern research increasingly uses data from wearable sensors such as GPS trackers and accelerometers. These devices record detailed information about an athlete’s speed, direction of movement, impacts, and overall physical load. At the same time, computer vision techniques are being applied to sports video, where algorithms can automatically detect motions, estimate body positions, or evaluate biomechanical patterns. Together, these technologies allow analysts to study movement quality, positional behavior, fatigue levels, and even predict injuries or long-term workload changes. [@AIWearables2024] These tools are most commonly found in higher division or well-funded athletic programs because those programs have access to expensive equipment and dedicated staff. Even then, they are usually used for training and monitoring rather than for competitive evaluation or recruiting.

Machine learning and artificial intelligence methods have also become important in this space. Deep learning models can process continuous sensor signals or video frames and automatically identify specific events such as sprints, jumps, or shots. They can monitor workload, detect abnormal stress patterns, or highlight inefficient movement styles. [@WearableSportsReview2024] This creates a much richer understanding of performance than what classical statistics can offer. Instead of only measuring outcomes like total hits or shots per game, these systems can evaluate reaction times, movement efficiency, recovery behavior, or potential biomechanical risk factors. Although these technologies offer advanced insights, they are often too expensive or too complex for lower-division schools, small colleges, and community programs.

Even with their potential, these advanced systems still face several important limitations. Many studies in wearable or vision-based analytics rely on small groups of athletes, often tested in controlled laboratory environments. This makes it difficult to determine whether the findings apply in actual competitive situations or across different levels of play. [@AIWearables2024] In addition, there is significant variation in the hardware and methods used across different research groups. Sensors may record at different sampling rates, follow different calibration steps, or use different preprocessing techniques before the data is analyzed. As a result, findings from one study cannot always be compared to another. An acceleration pattern identified in one dataset may not mean the same thing in another dataset if the devices or cleaning methods differ. [@DeepLearningAthlete2023] These inconsistencies show the need for centralized, standardized ways to manage and interpret athletic data.

Because of these issues, many of the most advanced analytics remain limited to elite or well-funded sports organizations. Problems with reproducibility, generalizability, and the high cost of technical equipment prevent widespread adoption. Lower-division programs, high schools, and smaller colleges struggle to access these tools, which increases inequality in the opportunities available to athletes.

A system like DataSeekr takes a different approach. Instead of depending on expensive wearable technologies or specialized vision systems, it relies on publicly available information such as official game statistics and records. While it may not provide the extremely detailed biomechanical measurements that advanced hardware can offer, it excels in accessibility and fairness. Because it uses data that all athletes can obtain, regardless of budget or resources, it creates a more equitable landscape. This allows a wider range of athletes and teams to participate in data-driven evaluation and analysis without the barriers imposed by cost or equipment.

## Web Scraping and Automated Data Collection

“Web scraping” means using automated software (bots) to retrieve data from web pages, parse relevant information, and store it in a structured form (e.g. CSV, database). For sports analytics, web scraping is often an attractive way to collect publicly available statistics, game logs, roster listings, highlight-video metadata, schedules, and more especially when no official API or bulk-export feature exists.

But scraping comes with serious ethical, legal, and technical considerations. Even if the data are public in principle, a website’s terms of service may forbid automated scraping or bulk harvesting. There are also potential copyright or database right issues, especially if the site collects and compiles data. According to recent research, as scraping becomes more widespread (for example to feed large language models or AI training sets), many site owners are tightening policies, making scraping riskier. [@EthicsScraping2024]

Beyond legal risks, scraping can impose real burdens on websites. If many bots crawl a site rapidly, it can degrade performance, cause partial outages, or trigger blocking. Ethical guidelines for responsible scraping recommend respecting rate-limits (delays between requests), obeying robots exclusion rules (robots.txt), avoiding repeated heavy access, and documenting provenance (where the data came from, when it was collected). [@EthicsScraping2024]

For DataSeekr, building a scraping-based ingestion system means you must embed these ethical/legal safeguards. By limiting collection to publicly available data, avoiding redistribution of copyrighted content, documenting provenance, and respecting site load, you reduce legal and ethical risk. That makes your system far more defensible than a “scrape first, ask forgiveness later” approach.

## Limitations of Existing Athlete Platforms

Many existing athlete platforms provide helpful tools such as highlight video hosting, recruiting profiles, and analytics dashboards. These platforms can be useful for players, coaches, and scouts because they allow athletes to share their performance and communicate with teams. However, even though these systems offer valuable features, they also contain problems that make them less fair and less effective for discovering talent across all levels of competition. These issues often make athletes feel that the process is unbalanced or biased.

One of the biggest challenges is something known as data lock in. This means that once an athlete uploads their videos or statistics to a specific platform, it becomes very difficult to move that information anywhere else. Some platforms do not allow exporting data at all, and others charge high prices for features that should be basic, such as downloading your own clips in high quality. This affects athletes directly. In my own experience, I used a recruiting service that required a very expensive payment to access the tools I needed. Since I did not have the money at the time, I missed opportunities that other players with more financial resources could access. Many athletes face similar obstacles, which limits fairness in the recruiting process.

Another issue is the difference in visibility between large, well funded programs and smaller schools. Athletes at major universities often appear on television, have dedicated camera crews, and receive high quality highlights automatically. Their plays look more professional, which naturally attracts more views and interest from scouts. Students at smaller colleges or high schools do not have this advantage. Their games may not be recorded, or the recordings may be low quality. For example, a player at a school like Allegheny might only have a few inconsistent videos, while a player at LSU will have every game broadcast and available online. This creates a major difference in visibility that has nothing to do with skill or performance. Instead, it is based on resources and exposure.

A third problem is the use of closed or proprietary evaluation systems. Some platforms give athletes a “player grade” or a “projectability score,” but they do not explain how these numbers were created. Without knowing the data behind the score or how the algorithm works, coaches and analysts cannot trust or verify what the rating means. This lack of transparency makes it difficult to compare players fairly. An athlete could receive a low rating for reasons that are not explained, which can negatively affect their chances even if they are talented.

Because of these limitations, many strong athletes remain overlooked simply because they lack access to high quality video, expensive subscriptions, or the right platform. DataSeekr aims to reduce this inequality. Instead of depending on paid uploads or hidden formulas, DataSeekr gathers publicly available information, organizes it in a consistent and clear structure, and provides both raw and calculated metrics in a transparent way. This creates a fairer environment where athletes from any background can be evaluated on their actual performance rather than on money, exposure, or platform design.

By presenting the data openly and treating every athlete the same, DataSeekr helps create a more equal recruiting landscape. Coaches and scouts can make better decisions because they are working with clean and trustworthy information. This approach gives athletes from all schools, big or small, a more realistic chance to be recognized.

## Gaps in Current Research and How DataSeekr Contributes

Even though sports analytics, data pipelines, and automated evaluation tools have grown quickly in recent years, there are still major gaps that make it hard for athletes, coaches, and researchers to work with data in a consistent and fair way. One of the most important problems is that there is no shared standard for sports data. Different projects collect data in different ways: some rely on wearable sensors, some use video-based tracking, and others manually gather box scores from websites. Each of these sources uses its own format, structure, and terminology. Because of this, it becomes very difficult to combine information from multiple sources or compare results between teams or seasons. Without standardization, long-term studies and reproducible research are often impossible, a challenge discussed widely in sports-analytics literature.

Another gap is related to data engineering, not just analysis. Many research papers or small projects collect data only once, in a short window of time. They rarely build long-term, maintainable data pipelines that can update information automatically. As a result, the data may slowly become outdated, inconsistent, or corrupted. This is a serious problem for sports analytics, since understanding athlete development or performance trends often requires reliable data over several years. If a system does not track where the data came from, when it was updated, and how it was cleaned, then later analysis may be inaccurate.

There is also a growing concern about ethics, legality, and data rights. Many sports-analytics systems collect data from websites without clearly documenting their methods. Some projects scrape information even when a website’s terms of service prohibit automated collection. Others combine athlete statistics with personal information without considering privacy rules or the athlete’s consent. According to recent studies on web data ethics, scraping without transparency or permission can violate site policies and raise legal risks for researchers or developers [@Akinwande2024ScrapingEthics]. These problems show that sports-data systems need better documentation, clearer permissions, and more ethical standards.

DataSeekr is designed specifically to address these gaps. Instead of depending on expensive wearable devices or privileged school resources, DataSeekr collects only publicly available information. It uses a clear and transparent pipeline that moves data from scraping → CSV → database → visualization. Every step is documented so users know exactly how the data was collected and processed. The system also exports data in a consistent, well-defined schema, which makes it easier for others to reuse the information or build additional tools on top of it.

Because DataSeekr focuses on standardization, accessibility, and transparency, it provides a more democratic alternative to many existing athlete-evaluation platforms. It allows schools, teams, and athletes especially those with fewer resources to access high-quality analytics without needing expensive equipment or special data sources. In the long term, DataSeekr could support broader research studies, help track athletes across multiple seasons, and encourage more open and fair practices in scouting and player evaluation.
